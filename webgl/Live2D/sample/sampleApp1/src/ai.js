export class AuctionAI {
  /**
   * @param {import('./path/to/LAppModel').LAppModel} model - à¸­à¸­à¸šà¹€à¸ˆà¹‡à¸à¸•à¹Œ Live2D model
   */
  constructor(model) {
    this.model = model;

    // à¹€à¸•à¸£à¸µà¸¢à¸¡à¸£à¸°à¸šà¸šà¹€à¸ªà¸µà¸¢à¸‡
    this.audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    this.analyser = this.audioCtx.createAnalyser();
    this.analyser.fftSize = 1024;

    this.dataArray = new Uint8Array(this.analyser.fftSize);
    this.lipSyncValue = 0;
  }

  /**
   * @param {'introduce'|'announceBid'|'prompt'|'announceWinner'} type
   * @param {any[]} data
   */
  async speak(type, data = []) {
    try {
      const res = await fetch('/api/ai', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ type, data })
      });

      const { text, audioBase64 } = await res.json();
      console.log('[AI] ðŸ—£ï¸ Text:', text);

      // à¸ªà¸£à¹‰à¸²à¸‡ audio object
      const audio = new Audio("data:audio/mp3;base64," + audioBase64);
      audio.play();

      // à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¹€à¸ªà¸µà¸¢à¸‡à¸à¸±à¸š analyzer
      const source = this.audioCtx.createMediaElementSource(audio);
      source.connect(this.analyser);
      this.analyser.connect(this.audioCtx.destination);

      // à¸„à¸³à¸™à¸§à¸“ waveform â†’ à¸„à¹ˆà¸² lipSyncValue
      const updateLipSync = () => {
        this.analyser.getByteTimeDomainData(this.dataArray);

        let sum = 0;
        for (let i = 0; i < this.dataArray.length; i++) {
          const val = (this.dataArray[i] - 128) / 128;
          sum += val * val;
        }

        this.lipSyncValue = Math.sqrt(sum / this.dataArray.length);

        if (!audio.paused && !audio.ended) {
          requestAnimationFrame(updateLipSync);
        } else {
          this.lipSyncValue = 0; // à¸«à¸¢à¸¸à¸”à¸‚à¸¢à¸±à¸šà¸›à¸²à¸
        }
      };

      updateLipSync();
    } catch (err) {
      console.error('[AuctionAI] speak() failed:', err);
    }
  }
}
